{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Model_development.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wkAzkFiOgVg"
      },
      "source": [
        "# Model Development \n",
        "\n",
        "After the task of cleaning the data, converting it into numeric format, feature selection and feature engineering. The data is finally in shape for developing a machine learning classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8Dv5f9OOgVr"
      },
      "source": [
        "# importing the libraries \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import validation_curve, train_test_split\n",
        "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
        "import xgboost"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "ixntHDx1OgVs",
        "outputId": "588f9bd4-9ca6-4358-d621-3ea248efdfba"
      },
      "source": [
        "df = pd.read_csv('ML_Artivatic_dataset/final_train.csv')\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>member_id</th>\n",
              "      <th>revol_bal</th>\n",
              "      <th>total_rev_hi_lim</th>\n",
              "      <th>collection_recovery_fee</th>\n",
              "      <th>delinq_2yrs</th>\n",
              "      <th>revol_util</th>\n",
              "      <th>pub_rec</th>\n",
              "      <th>recoveries</th>\n",
              "      <th>open_acc</th>\n",
              "      <th>inq_last_6mths</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>funded_amnt</th>\n",
              "      <th>funded_amnt_inv</th>\n",
              "      <th>term</th>\n",
              "      <th>dti</th>\n",
              "      <th>last_week_pay</th>\n",
              "      <th>grade</th>\n",
              "      <th>purpose</th>\n",
              "      <th>home_ownership</th>\n",
              "      <th>verification_status</th>\n",
              "      <th>initial_list_status</th>\n",
              "      <th>loan_to_income</th>\n",
              "      <th>bad_state</th>\n",
              "      <th>avl_lines</th>\n",
              "      <th>int_paid</th>\n",
              "      <th>emi_paid_progress_perc</th>\n",
              "      <th>total_repayment_progress</th>\n",
              "      <th>loan_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58189336</td>\n",
              "      <td>22515.0</td>\n",
              "      <td>30800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14350</td>\n",
              "      <td>14350</td>\n",
              "      <td>14350.0</td>\n",
              "      <td>36</td>\n",
              "      <td>33.88</td>\n",
              "      <td>26</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1173.84</td>\n",
              "      <td>16.560510</td>\n",
              "      <td>16.560510</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>70011223</td>\n",
              "      <td>7624.0</td>\n",
              "      <td>32900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4800</td>\n",
              "      <td>4800</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>36</td>\n",
              "      <td>3.64</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13.541667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>83.95</td>\n",
              "      <td>5.732484</td>\n",
              "      <td>5.732484</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70255675</td>\n",
              "      <td>10877.0</td>\n",
              "      <td>34900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>36</td>\n",
              "      <td>18.42</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>56.47</td>\n",
              "      <td>5.732484</td>\n",
              "      <td>5.732484</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1893936</td>\n",
              "      <td>13712.0</td>\n",
              "      <td>24700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15000</td>\n",
              "      <td>15000</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>36</td>\n",
              "      <td>14.97</td>\n",
              "      <td>135</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4858.62</td>\n",
              "      <td>85.987261</td>\n",
              "      <td>85.987261</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7652106</td>\n",
              "      <td>35835.0</td>\n",
              "      <td>47033.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16000</td>\n",
              "      <td>16000</td>\n",
              "      <td>16000.0</td>\n",
              "      <td>36</td>\n",
              "      <td>20.16</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2296.41</td>\n",
              "      <td>61.146497</td>\n",
              "      <td>61.146497</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532423</th>\n",
              "      <td>31296187</td>\n",
              "      <td>15775.0</td>\n",
              "      <td>24800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>63.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20000</td>\n",
              "      <td>20000</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>36</td>\n",
              "      <td>14.53</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2595.45</td>\n",
              "      <td>41.401274</td>\n",
              "      <td>41.401274</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532424</th>\n",
              "      <td>29403184</td>\n",
              "      <td>9453.0</td>\n",
              "      <td>17800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12000</td>\n",
              "      <td>12000</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>60</td>\n",
              "      <td>22.97</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.916667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2182.92</td>\n",
              "      <td>26.819923</td>\n",
              "      <td>26.819923</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532425</th>\n",
              "      <td>7357607</td>\n",
              "      <td>12085.0</td>\n",
              "      <td>24200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18725</td>\n",
              "      <td>18725</td>\n",
              "      <td>18725.0</td>\n",
              "      <td>60</td>\n",
              "      <td>27.27</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.269907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>645.32</td>\n",
              "      <td>3.448276</td>\n",
              "      <td>3.448276</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532426</th>\n",
              "      <td>23182668</td>\n",
              "      <td>20902.0</td>\n",
              "      <td>23300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21000</td>\n",
              "      <td>21000</td>\n",
              "      <td>21000.0</td>\n",
              "      <td>60</td>\n",
              "      <td>14.91</td>\n",
              "      <td>78</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.380952</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4619.79</td>\n",
              "      <td>29.885057</td>\n",
              "      <td>29.885057</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532427</th>\n",
              "      <td>46122259</td>\n",
              "      <td>10058.0</td>\n",
              "      <td>21700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>36</td>\n",
              "      <td>17.80</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>467.52</td>\n",
              "      <td>28.025478</td>\n",
              "      <td>28.025478</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>532428 rows Ã— 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        member_id  revol_bal  ...  total_repayment_progress  loan_status\n",
              "0        58189336    22515.0  ...                 16.560510            0\n",
              "1        70011223     7624.0  ...                  5.732484            0\n",
              "2        70255675    10877.0  ...                  5.732484            0\n",
              "3         1893936    13712.0  ...                 85.987261            0\n",
              "4         7652106    35835.0  ...                 61.146497            0\n",
              "...           ...        ...  ...                       ...          ...\n",
              "532423   31296187    15775.0  ...                 41.401274            0\n",
              "532424   29403184     9453.0  ...                 26.819923            0\n",
              "532425    7357607    12085.0  ...                  3.448276            1\n",
              "532426   23182668    20902.0  ...                 29.885057            0\n",
              "532427   46122259    10058.0  ...                 28.025478            0\n",
              "\n",
              "[532428 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzSfNjqXOgVx"
      },
      "source": [
        "cols = df.columns.values.tolist()\n",
        "cols.remove('member_id')\n",
        "cols.remove('loan_status')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGaceD8fOgVz",
        "outputId": "58e80f0e-ea22-4d37-aa06-78e2e09baf4f"
      },
      "source": [
        "X_train = df[cols]\n",
        "\n",
        "y_train = df['loan_status']\n",
        "\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer(strategy='median')\n",
        "X_train = pd.DataFrame(imp.fit_transform(X_train))\n",
        "\n",
        "# Split train and cross validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.30)\n",
        "eval_set=[(X_test, y_test)]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4389: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PoAK5BPOgV2"
      },
      "source": [
        "## Random Forest Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHRDN7ZTOgV3",
        "outputId": "8f9c2189-fa43-4c49-8de9-7e82d672c3c6"
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, verbose=5, n_jobs=-1)\n",
        "rf.fit(np.array(X_train), np.array(y_train))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 100building tree 2 of 100\n",
            "\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   19.4s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n",
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  1.6min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=None, verbose=5,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MiENpcoOgV4",
        "outputId": "d9049891-4cda-40b5-b70c-8501f1a6ff57"
      },
      "source": [
        "rf_perf = roc_auc_score(y_test, rf.predict(X_test))\n",
        "rf_perf"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    5.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6786121781658906"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki-sOzE_PUGj"
      },
      "source": [
        "## SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe7-6Z0SOgV5",
        "outputId": "656b3d7e-2286-4404-c17b-7a6083702100"
      },
      "source": [
        "sgd = SGDClassifier(loss='modified_huber', verbose=2, n_jobs=-1, max_iter=1000)\n",
        "sgd.fit(X_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 3882376.97, NNZs: 26, Bias: 10477.522090, T: 372699, Avg. loss: 1719816217.704885\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1933799.50, NNZs: 26, Bias: 11410.791628, T: 745398, Avg. loss: 181970232.487601\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1287456.57, NNZs: 26, Bias: 11733.297810, T: 1118097, Avg. loss: 103674246.886530\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 964446.83, NNZs: 26, Bias: 11865.311020, T: 1490796, Avg. loss: 72105072.555572\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 770284.67, NNZs: 26, Bias: 11915.747549, T: 1863495, Avg. loss: 53542668.652848\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 640462.76, NNZs: 26, Bias: 11935.475134, T: 2236194, Avg. loss: 43372096.065837\n",
            "Total training time: 0.61 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 547645.44, NNZs: 26, Bias: 11944.098451, T: 2608893, Avg. loss: 37255301.403159\n",
            "Total training time: 0.72 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 477916.32, NNZs: 26, Bias: 11947.599707, T: 2981592, Avg. loss: 40326304.851374\n",
            "Total training time: 0.82 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 423666.89, NNZs: 26, Bias: 11948.586408, T: 3354291, Avg. loss: 28751925.590506\n",
            "Total training time: 0.92 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 380269.55, NNZs: 26, Bias: 11949.212200, T: 3726990, Avg. loss: 32283284.629220\n",
            "Total training time: 1.02 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 344630.61, NNZs: 26, Bias: 11948.668563, T: 4099689, Avg. loss: 22759883.268049\n",
            "Total training time: 1.12 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 314947.71, NNZs: 26, Bias: 11948.956928, T: 4472388, Avg. loss: 20702449.891829\n",
            "Total training time: 1.22 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 289815.95, NNZs: 26, Bias: 11947.826546, T: 4845087, Avg. loss: 18923839.306481\n",
            "Total training time: 1.32 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 268332.96, NNZs: 26, Bias: 11950.955185, T: 5217786, Avg. loss: 22549150.663572\n",
            "Total training time: 1.41 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 249655.75, NNZs: 26, Bias: 11951.496926, T: 5590485, Avg. loss: 16627059.766359\n",
            "Total training time: 1.51 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 233344.79, NNZs: 26, Bias: 11951.684842, T: 5963184, Avg. loss: 15683932.581963\n",
            "Total training time: 1.61 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 218941.86, NNZs: 26, Bias: 11953.822631, T: 6335883, Avg. loss: 14282653.515659\n",
            "Total training time: 1.72 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 206190.79, NNZs: 26, Bias: 11956.746563, T: 6708582, Avg. loss: 13856177.132010\n",
            "Total training time: 1.81 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 194761.73, NNZs: 26, Bias: 11959.657658, T: 7081281, Avg. loss: 12829175.396187\n",
            "Total training time: 1.91 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 184476.08, NNZs: 26, Bias: 11963.633182, T: 7453980, Avg. loss: 15311935.248447\n",
            "Total training time: 2.02 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 175122.60, NNZs: 26, Bias: 11965.955780, T: 7826679, Avg. loss: 11529684.720527\n",
            "Total training time: 2.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 166649.61, NNZs: 26, Bias: 11968.452613, T: 8199378, Avg. loss: 11082329.554702\n",
            "Total training time: 2.21 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 158921.94, NNZs: 26, Bias: 11973.233230, T: 8572077, Avg. loss: 13295878.667471\n",
            "Total training time: 2.32 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 151860.59, NNZs: 26, Bias: 11977.445669, T: 8944776, Avg. loss: 12721780.314240\n",
            "Total training time: 2.42 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 145353.41, NNZs: 26, Bias: 11981.755081, T: 9317475, Avg. loss: 12267222.200532\n",
            "Total training time: 2.52 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 139307.00, NNZs: 26, Bias: 11984.850584, T: 9690174, Avg. loss: 9348711.237192\n",
            "Total training time: 2.63 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 133731.78, NNZs: 26, Bias: 11987.646043, T: 10062873, Avg. loss: 9155174.027730\n",
            "Total training time: 2.74 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 128584.62, NNZs: 26, Bias: 11991.526937, T: 10435572, Avg. loss: 8664231.390741\n",
            "Total training time: 2.83 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 123825.46, NNZs: 26, Bias: 11996.548434, T: 10808271, Avg. loss: 10355927.072584\n",
            "Total training time: 2.93 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 119350.06, NNZs: 26, Bias: 12000.117071, T: 11180970, Avg. loss: 10266336.165284\n",
            "Total training time: 3.03 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 115135.80, NNZs: 26, Bias: 12003.259509, T: 11553669, Avg. loss: 7700205.327791\n",
            "Total training time: 3.13 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 111197.76, NNZs: 26, Bias: 12007.296196, T: 11926368, Avg. loss: 7791448.117246\n",
            "Total training time: 3.24 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 107495.70, NNZs: 26, Bias: 12011.260371, T: 12299067, Avg. loss: 7304670.759184\n",
            "Total training time: 3.34 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 104042.55, NNZs: 26, Bias: 12014.459375, T: 12671766, Avg. loss: 8905839.092895\n",
            "Total training time: 3.44 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 100785.03, NNZs: 26, Bias: 12018.061977, T: 13044465, Avg. loss: 6952377.384287\n",
            "Total training time: 3.54 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 97690.41, NNZs: 26, Bias: 12021.547329, T: 13417164, Avg. loss: 6845959.861430\n",
            "Total training time: 3.64 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 94748.57, NNZs: 26, Bias: 12024.534139, T: 13789863, Avg. loss: 6679857.224634\n",
            "Total training time: 3.75 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 91999.10, NNZs: 26, Bias: 12027.998534, T: 14162562, Avg. loss: 6438990.047028\n",
            "Total training time: 3.86 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 89388.74, NNZs: 26, Bias: 12031.650038, T: 14535261, Avg. loss: 6046995.237540\n",
            "Total training time: 3.97 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 86919.23, NNZs: 26, Bias: 12035.541357, T: 14907960, Avg. loss: 7512104.264959\n",
            "Total training time: 4.07 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 84562.51, NNZs: 26, Bias: 12039.306253, T: 15280659, Avg. loss: 7385011.537357\n",
            "Total training time: 4.17 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 82323.18, NNZs: 26, Bias: 12042.373676, T: 15653358, Avg. loss: 7280982.723540\n",
            "Total training time: 4.27 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 80172.59, NNZs: 26, Bias: 12045.538718, T: 16026057, Avg. loss: 5736488.664964\n",
            "Total training time: 4.37 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 78147.39, NNZs: 26, Bias: 12048.851948, T: 16398756, Avg. loss: 6790166.526893\n",
            "Total training time: 4.47 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 76197.93, NNZs: 26, Bias: 12052.158176, T: 16771455, Avg. loss: 5372512.386739\n",
            "Total training time: 4.57 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 74323.59, NNZs: 26, Bias: 12054.953288, T: 17144154, Avg. loss: 5311736.725653\n",
            "Total training time: 4.66 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 72547.98, NNZs: 26, Bias: 12057.937628, T: 17516853, Avg. loss: 6475366.498997\n",
            "Total training time: 4.76 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 70843.97, NNZs: 26, Bias: 12060.792302, T: 17889552, Avg. loss: 4998623.496698\n",
            "Total training time: 4.87 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 69203.84, NNZs: 26, Bias: 12063.613469, T: 18262251, Avg. loss: 4855704.478317\n",
            "Total training time: 4.97 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 67645.01, NNZs: 26, Bias: 12067.000432, T: 18634950, Avg. loss: 4830108.429608\n",
            "Total training time: 5.06 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 66120.46, NNZs: 26, Bias: 12069.746854, T: 19007649, Avg. loss: 4625591.003596\n",
            "Total training time: 5.17 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 64691.90, NNZs: 26, Bias: 12072.771475, T: 19380348, Avg. loss: 5768097.282653\n",
            "Total training time: 5.27 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 63313.22, NNZs: 26, Bias: 12075.699349, T: 19753047, Avg. loss: 5760467.558811\n",
            "Total training time: 5.37 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 62001.91, NNZs: 26, Bias: 12078.625290, T: 20125746, Avg. loss: 5655891.777039\n",
            "Total training time: 5.47 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 60711.32, NNZs: 26, Bias: 12080.865164, T: 20498445, Avg. loss: 4375616.398100\n",
            "Total training time: 5.57 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 59491.04, NNZs: 26, Bias: 12083.295152, T: 20871144, Avg. loss: 5415269.198586\n",
            "Total training time: 5.67 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 58314.13, NNZs: 26, Bias: 12086.194030, T: 21243843, Avg. loss: 4306335.825566\n",
            "Total training time: 5.77 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 57164.57, NNZs: 26, Bias: 12089.164598, T: 21616542, Avg. loss: 4170423.106509\n",
            "Total training time: 5.87 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 56046.15, NNZs: 26, Bias: 12091.397367, T: 21989241, Avg. loss: 4034955.484595\n",
            "Total training time: 5.97 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 54969.06, NNZs: 26, Bias: 12093.488756, T: 22361940, Avg. loss: 4023071.091304\n",
            "Total training time: 6.07 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 53943.33, NNZs: 26, Bias: 12095.821021, T: 22734639, Avg. loss: 3990863.648130\n",
            "Total training time: 6.17 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 52948.76, NNZs: 26, Bias: 12098.360105, T: 23107338, Avg. loss: 3804082.851329\n",
            "Total training time: 6.27 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 51996.19, NNZs: 26, Bias: 12101.058165, T: 23480037, Avg. loss: 3852877.489387\n",
            "Total training time: 6.36 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 51069.26, NNZs: 26, Bias: 12103.341197, T: 23852736, Avg. loss: 3826278.482187\n",
            "Total training time: 6.46 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 50162.24, NNZs: 26, Bias: 12105.682711, T: 24225435, Avg. loss: 3553105.330810\n",
            "Total training time: 6.56 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 49299.92, NNZs: 26, Bias: 12108.092715, T: 24598134, Avg. loss: 3659888.224858\n",
            "Total training time: 6.65 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 48453.50, NNZs: 26, Bias: 12110.391613, T: 24970833, Avg. loss: 3621459.456848\n",
            "Total training time: 6.76 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 47630.74, NNZs: 26, Bias: 12112.824649, T: 25343532, Avg. loss: 3471802.437275\n",
            "Total training time: 6.86 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 46832.48, NNZs: 26, Bias: 12115.108022, T: 25716231, Avg. loss: 3457530.132436\n",
            "Total training time: 6.96 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 46080.26, NNZs: 26, Bias: 12117.395630, T: 26088930, Avg. loss: 4281891.774346\n",
            "Total training time: 7.06 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 45328.84, NNZs: 26, Bias: 12119.261769, T: 26461629, Avg. loss: 3391116.515860\n",
            "Total training time: 7.16 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 44597.08, NNZs: 26, Bias: 12121.396743, T: 26834328, Avg. loss: 3302102.919571\n",
            "Total training time: 7.25 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 43891.58, NNZs: 26, Bias: 12123.554599, T: 27207027, Avg. loss: 3262680.999607\n",
            "Total training time: 7.35 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 43213.93, NNZs: 26, Bias: 12125.855282, T: 27579726, Avg. loss: 4011902.075012\n",
            "Total training time: 7.45 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 42553.46, NNZs: 26, Bias: 12128.111453, T: 27952425, Avg. loss: 3164032.911168\n",
            "Total training time: 7.55 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 41910.20, NNZs: 26, Bias: 12130.066154, T: 28325124, Avg. loss: 3903656.058069\n",
            "Total training time: 7.65 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 41287.15, NNZs: 26, Bias: 12132.069818, T: 28697823, Avg. loss: 3175040.886226\n",
            "Total training time: 7.75 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 40677.61, NNZs: 26, Bias: 12133.786598, T: 29070522, Avg. loss: 3003265.586450\n",
            "Total training time: 7.85 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 40094.39, NNZs: 26, Bias: 12135.774743, T: 29443221, Avg. loss: 3795225.230463\n",
            "Total training time: 7.95 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 39518.98, NNZs: 26, Bias: 12137.703836, T: 29815920, Avg. loss: 2972706.330830\n",
            "Total training time: 8.05 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 38963.70, NNZs: 26, Bias: 12139.287548, T: 30188619, Avg. loss: 2941118.239528\n",
            "Total training time: 8.15 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 38439.46, NNZs: 26, Bias: 12141.538961, T: 30561318, Avg. loss: 3691722.555607\n",
            "Total training time: 8.25 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 37893.03, NNZs: 26, Bias: 12143.003391, T: 30934017, Avg. loss: 2871128.891517\n",
            "Total training time: 8.35 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 37395.95, NNZs: 26, Bias: 12144.863255, T: 31306716, Avg. loss: 3507956.794162\n",
            "Total training time: 8.45 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 512032.34, NNZs: 26, Bias: 12173.308835, T: 31679415, Avg. loss: 14112720.176328\n",
            "Total training time: 8.54 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 502431.62, NNZs: 26, Bias: 12217.176589, T: 32052114, Avg. loss: 19452646.743607\n",
            "Total training time: 8.64 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 493183.58, NNZs: 26, Bias: 12259.777775, T: 32424813, Avg. loss: 19169287.140826\n",
            "Total training time: 8.74 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 484255.00, NNZs: 26, Bias: 12301.095002, T: 32797512, Avg. loss: 17688563.705071\n",
            "Total training time: 8.84 seconds.\n",
            "Convergence after 88 epochs took 8.84 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
              "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTXUmA42OgV7",
        "outputId": "1c17faea-adac-40f0-a484-486bd2684f12"
      },
      "source": [
        "sgd_perf = roc_auc_score(y_test, sgd.predict(X_test))\n",
        "sgd_perf"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4526338615851597"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAiK1AENPqkE"
      },
      "source": [
        "## KNeighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgnnxLcUOgV9",
        "outputId": "9a9bc16c-aaea-4d0a-c125-1c961889ef61"
      },
      "source": [
        "knc = KNeighborsClassifier(n_neighbors=20, n_jobs=-1)\n",
        "knc.fit(X_train, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=-1, n_neighbors=20, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlV_bEDlOgV9",
        "outputId": "27911390-374a-422d-800a-72642587d72e"
      },
      "source": [
        "knc_perf = roc_auc_score(y_test, knc.predict(X_test))\n",
        "knc_perf"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6112162383370338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeoD5iVXP0Ri"
      },
      "source": [
        "## Gradient Boosting Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJlNUW4hOgV-",
        "outputId": "1b95c902-db1f-4ecf-e8ad-75047f47256a"
      },
      "source": [
        "gbc = GradientBoostingClassifier(n_estimators=1000, max_depth=5, verbose=2)\n",
        "gbc.fit(X_train, y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.0586           52.54m\n",
            "         2           1.0216           58.02m\n",
            "         3           0.9934           60.09m\n",
            "         4           0.9718           58.38m\n",
            "         5           0.9582           57.28m\n",
            "         6           0.9458           56.32m\n",
            "         7           0.9360           55.75m\n",
            "         8           0.9236           55.52m\n",
            "         9           0.9161           55.17m\n",
            "        10           0.9093           55.23m\n",
            "        11           0.9036           55.22m\n",
            "        12           0.8946           55.29m\n",
            "        13           0.8895           55.27m\n",
            "        14           0.8825           55.28m\n",
            "        15           0.8771           55.35m\n",
            "        16           0.8719           55.18m\n",
            "        17           0.8680           54.95m\n",
            "        18           0.8650           54.65m\n",
            "        19           0.8622           54.34m\n",
            "        20           0.8584           54.00m\n",
            "        21           0.8543           53.93m\n",
            "        22           0.8494           53.84m\n",
            "        23           0.8472           53.63m\n",
            "        24           0.8433           53.47m\n",
            "        25           0.8410           53.35m\n",
            "        26           0.8374           53.19m\n",
            "        27           0.8356           53.05m\n",
            "        28           0.8337           52.90m\n",
            "        29           0.8321           52.75m\n",
            "        30           0.8301           52.57m\n",
            "        31           0.8272           52.46m\n",
            "        32           0.8257           52.31m\n",
            "        33           0.8244           52.14m\n",
            "        34           0.8229           52.03m\n",
            "        35           0.8218           51.95m\n",
            "        36           0.8197           51.83m\n",
            "        37           0.8186           51.65m\n",
            "        38           0.8175           51.48m\n",
            "        39           0.8166           51.36m\n",
            "        40           0.8155           51.25m\n",
            "        41           0.8142           51.15m\n",
            "        42           0.8134           50.98m\n",
            "        43           0.8123           50.83m\n",
            "        44           0.8109           50.67m\n",
            "        45           0.8096           50.54m\n",
            "        46           0.8087           50.43m\n",
            "        47           0.8066           50.32m\n",
            "        48           0.8056           50.22m\n",
            "        49           0.8039           50.09m\n",
            "        50           0.8031           50.00m\n",
            "        51           0.8024           49.90m\n",
            "        52           0.8015           49.81m\n",
            "        53           0.8008           49.73m\n",
            "        54           0.7993           49.64m\n",
            "        55           0.7985           49.53m\n",
            "        56           0.7979           49.47m\n",
            "        57           0.7971           49.39m\n",
            "        58           0.7957           49.30m\n",
            "        59           0.7952           49.21m\n",
            "        60           0.7945           49.12m\n",
            "        61           0.7940           49.02m\n",
            "        62           0.7934           48.90m\n",
            "        63           0.7922           48.81m\n",
            "        64           0.7918           48.71m\n",
            "        65           0.7909           48.63m\n",
            "        66           0.7897           48.56m\n",
            "        67           0.7888           48.50m\n",
            "        68           0.7880           48.42m\n",
            "        69           0.7876           48.35m\n",
            "        70           0.7868           48.30m\n",
            "        71           0.7863           48.20m\n",
            "        72           0.7855           48.12m\n",
            "        73           0.7848           48.07m\n",
            "        74           0.7845           47.99m\n",
            "        75           0.7840           47.90m\n",
            "        76           0.7836           47.83m\n",
            "        77           0.7824           47.76m\n",
            "        78           0.7820           47.70m\n",
            "        79           0.7810           47.63m\n",
            "        80           0.7805           47.54m\n",
            "        81           0.7800           47.45m\n",
            "        82           0.7793           47.40m\n",
            "        83           0.7787           47.33m\n",
            "        84           0.7781           47.27m\n",
            "        85           0.7778           47.19m\n",
            "        86           0.7768           47.13m\n",
            "        87           0.7766           47.06m\n",
            "        88           0.7753           46.99m\n",
            "        89           0.7741           46.92m\n",
            "        90           0.7730           46.86m\n",
            "        91           0.7726           46.80m\n",
            "        92           0.7723           46.73m\n",
            "        93           0.7720           46.65m\n",
            "        94           0.7715           46.60m\n",
            "        95           0.7712           46.55m\n",
            "        96           0.7701           46.51m\n",
            "        97           0.7698           46.43m\n",
            "        98           0.7692           46.35m\n",
            "        99           0.7687           46.30m\n",
            "       100           0.7683           46.24m\n",
            "       101           0.7675           46.18m\n",
            "       102           0.7669           46.16m\n",
            "       103           0.7660           46.13m\n",
            "       104           0.7656           46.07m\n",
            "       105           0.7650           46.01m\n",
            "       106           0.7646           45.95m\n",
            "       107           0.7643           45.89m\n",
            "       108           0.7635           45.84m\n",
            "       109           0.7633           45.77m\n",
            "       110           0.7628           45.72m\n",
            "       111           0.7625           45.65m\n",
            "       112           0.7619           45.59m\n",
            "       113           0.7616           45.52m\n",
            "       114           0.7611           45.47m\n",
            "       115           0.7608           45.41m\n",
            "       116           0.7603           45.36m\n",
            "       117           0.7596           45.32m\n",
            "       118           0.7591           45.26m\n",
            "       119           0.7583           45.21m\n",
            "       120           0.7578           45.19m\n",
            "       121           0.7573           45.16m\n",
            "       122           0.7570           45.29m\n",
            "       123           0.7567           45.39m\n",
            "       124           0.7564           45.33m\n",
            "       125           0.7558           45.26m\n",
            "       126           0.7553           45.19m\n",
            "       127           0.7548           45.12m\n",
            "       128           0.7545           45.06m\n",
            "       129           0.7540           45.00m\n",
            "       130           0.7534           44.93m\n",
            "       131           0.7525           44.87m\n",
            "       132           0.7523           44.80m\n",
            "       133           0.7518           44.73m\n",
            "       134           0.7514           44.68m\n",
            "       135           0.7510           44.61m\n",
            "       136           0.7508           44.56m\n",
            "       137           0.7505           44.50m\n",
            "       138           0.7503           44.42m\n",
            "       139           0.7499           44.37m\n",
            "       140           0.7489           44.30m\n",
            "       141           0.7483           44.24m\n",
            "       142           0.7479           44.17m\n",
            "       143           0.7477           44.11m\n",
            "       144           0.7473           44.06m\n",
            "       145           0.7465           44.01m\n",
            "       146           0.7463           43.97m\n",
            "       147           0.7459           43.91m\n",
            "       148           0.7454           43.86m\n",
            "       149           0.7452           43.79m\n",
            "       150           0.7450           43.74m\n",
            "       151           0.7447           43.68m\n",
            "       152           0.7440           43.63m\n",
            "       153           0.7436           43.57m\n",
            "       154           0.7431           43.53m\n",
            "       155           0.7426           43.47m\n",
            "       156           0.7422           43.43m\n",
            "       157           0.7415           43.39m\n",
            "       158           0.7411           43.34m\n",
            "       159           0.7408           43.29m\n",
            "       160           0.7405           43.24m\n",
            "       161           0.7404           43.18m\n",
            "       162           0.7403           43.13m\n",
            "       163           0.7400           43.07m\n",
            "       164           0.7396           43.01m\n",
            "       165           0.7395           42.95m\n",
            "       166           0.7394           42.88m\n",
            "       167           0.7391           42.83m\n",
            "       168           0.7384           42.78m\n",
            "       169           0.7381           42.73m\n",
            "       170           0.7378           42.67m\n",
            "       171           0.7374           42.61m\n",
            "       172           0.7369           42.56m\n",
            "       173           0.7364           42.51m\n",
            "       174           0.7361           42.46m\n",
            "       175           0.7358           42.41m\n",
            "       176           0.7355           42.36m\n",
            "       177           0.7352           42.30m\n",
            "       178           0.7350           42.26m\n",
            "       179           0.7347           42.20m\n",
            "       180           0.7344           42.15m\n",
            "       181           0.7340           42.10m\n",
            "       182           0.7337           42.04m\n",
            "       183           0.7335           41.99m\n",
            "       184           0.7332           41.93m\n",
            "       185           0.7329           41.87m\n",
            "       186           0.7325           41.81m\n",
            "       187           0.7323           41.75m\n",
            "       188           0.7319           41.70m\n",
            "       189           0.7316           41.64m\n",
            "       190           0.7313           41.58m\n",
            "       191           0.7310           41.52m\n",
            "       192           0.7307           41.47m\n",
            "       193           0.7303           41.41m\n",
            "       194           0.7300           41.35m\n",
            "       195           0.7298           41.28m\n",
            "       196           0.7296           41.22m\n",
            "       197           0.7293           41.17m\n",
            "       198           0.7290           41.11m\n",
            "       199           0.7288           41.05m\n",
            "       200           0.7283           40.99m\n",
            "       201           0.7281           40.92m\n",
            "       202           0.7279           40.86m\n",
            "       203           0.7276           40.83m\n",
            "       204           0.7273           40.78m\n",
            "       205           0.7272           40.72m\n",
            "       206           0.7267           40.67m\n",
            "       207           0.7263           40.61m\n",
            "       208           0.7260           40.56m\n",
            "       209           0.7256           40.50m\n",
            "       210           0.7254           40.45m\n",
            "       211           0.7251           40.39m\n",
            "       212           0.7247           40.34m\n",
            "       213           0.7245           40.28m\n",
            "       214           0.7243           40.23m\n",
            "       215           0.7241           40.18m\n",
            "       216           0.7238           40.12m\n",
            "       217           0.7233           40.07m\n",
            "       218           0.7231           40.02m\n",
            "       219           0.7229           39.98m\n",
            "       220           0.7227           39.92m\n",
            "       221           0.7224           39.88m\n",
            "       222           0.7221           39.85m\n",
            "       223           0.7218           39.81m\n",
            "       224           0.7216           39.77m\n",
            "       225           0.7213           39.74m\n",
            "       226           0.7210           39.71m\n",
            "       227           0.7209           39.68m\n",
            "       228           0.7207           39.62m\n",
            "       229           0.7204           39.58m\n",
            "       230           0.7202           39.53m\n",
            "       231           0.7199           39.48m\n",
            "       232           0.7196           39.44m\n",
            "       233           0.7194           39.39m\n",
            "       234           0.7191           39.34m\n",
            "       235           0.7189           39.29m\n",
            "       236           0.7186           39.25m\n",
            "       237           0.7183           39.21m\n",
            "       238           0.7180           39.16m\n",
            "       239           0.7179           39.10m\n",
            "       240           0.7175           39.06m\n",
            "       241           0.7172           39.01m\n",
            "       242           0.7170           38.97m\n",
            "       243           0.7167           38.92m\n",
            "       244           0.7165           38.87m\n",
            "       245           0.7163           38.83m\n",
            "       246           0.7160           38.78m\n",
            "       247           0.7158           38.73m\n",
            "       248           0.7155           38.69m\n",
            "       249           0.7151           38.64m\n",
            "       250           0.7149           38.59m\n",
            "       251           0.7146           38.55m\n",
            "       252           0.7143           38.50m\n",
            "       253           0.7141           38.45m\n",
            "       254           0.7138           38.40m\n",
            "       255           0.7135           38.35m\n",
            "       256           0.7133           38.30m\n",
            "       257           0.7132           38.25m\n",
            "       258           0.7130           38.20m\n",
            "       259           0.7127           38.14m\n",
            "       260           0.7124           38.09m\n",
            "       261           0.7122           38.04m\n",
            "       262           0.7121           37.99m\n",
            "       263           0.7119           37.94m\n",
            "       264           0.7117           37.89m\n",
            "       265           0.7115           37.84m\n",
            "       266           0.7112           37.79m\n",
            "       267           0.7110           37.74m\n",
            "       268           0.7108           37.68m\n",
            "       269           0.7105           37.63m\n",
            "       270           0.7103           37.58m\n",
            "       271           0.7100           37.53m\n",
            "       272           0.7099           37.48m\n",
            "       273           0.7097           37.42m\n",
            "       274           0.7094           37.37m\n",
            "       275           0.7091           37.32m\n",
            "       276           0.7090           37.27m\n",
            "       277           0.7087           37.22m\n",
            "       278           0.7085           37.16m\n",
            "       279           0.7083           37.11m\n",
            "       280           0.7080           37.06m\n",
            "       281           0.7079           37.00m\n",
            "       282           0.7076           36.95m\n",
            "       283           0.7074           36.90m\n",
            "       284           0.7072           36.85m\n",
            "       285           0.7069           36.80m\n",
            "       286           0.7067           36.74m\n",
            "       287           0.7065           36.69m\n",
            "       288           0.7063           36.64m\n",
            "       289           0.7061           36.59m\n",
            "       290           0.7060           36.53m\n",
            "       291           0.7058           36.48m\n",
            "       292           0.7056           36.42m\n",
            "       293           0.7054           36.37m\n",
            "       294           0.7052           36.32m\n",
            "       295           0.7050           36.27m\n",
            "       296           0.7047           36.22m\n",
            "       297           0.7045           36.16m\n",
            "       298           0.7042           36.11m\n",
            "       299           0.7041           36.06m\n",
            "       300           0.7039           36.01m\n",
            "       301           0.7037           35.96m\n",
            "       302           0.7035           35.93m\n",
            "       303           0.7033           35.89m\n",
            "       304           0.7032           35.83m\n",
            "       305           0.7030           35.78m\n",
            "       306           0.7028           35.73m\n",
            "       307           0.7026           35.68m\n",
            "       308           0.7024           35.63m\n",
            "       309           0.7022           35.58m\n",
            "       310           0.7020           35.53m\n",
            "       311           0.7018           35.48m\n",
            "       312           0.7017           35.43m\n",
            "       313           0.7015           35.38m\n",
            "       314           0.7013           35.33m\n",
            "       315           0.7011           35.28m\n",
            "       316           0.7009           35.22m\n",
            "       317           0.7007           35.17m\n",
            "       318           0.7005           35.12m\n",
            "       319           0.7003           35.08m\n",
            "       320           0.7001           35.03m\n",
            "       321           0.7000           34.98m\n",
            "       322           0.6997           34.92m\n",
            "       323           0.6996           34.87m\n",
            "       324           0.6994           34.83m\n",
            "       325           0.6991           34.79m\n",
            "       326           0.6989           34.75m\n",
            "       327           0.6988           34.71m\n",
            "       328           0.6986           34.67m\n",
            "       329           0.6985           34.64m\n",
            "       330           0.6984           34.60m\n",
            "       331           0.6982           34.55m\n",
            "       332           0.6980           34.50m\n",
            "       333           0.6979           34.45m\n",
            "       334           0.6977           34.39m\n",
            "       335           0.6975           34.34m\n",
            "       336           0.6973           34.28m\n",
            "       337           0.6970           34.23m\n",
            "       338           0.6969           34.17m\n",
            "       339           0.6967           34.12m\n",
            "       340           0.6965           34.07m\n",
            "       341           0.6963           34.01m\n",
            "       342           0.6961           33.95m\n",
            "       343           0.6960           33.90m\n",
            "       344           0.6958           33.84m\n",
            "       345           0.6956           33.79m\n",
            "       346           0.6955           33.73m\n",
            "       347           0.6954           33.68m\n",
            "       348           0.6952           33.63m\n",
            "       349           0.6951           33.57m\n",
            "       350           0.6949           33.52m\n",
            "       351           0.6948           33.46m\n",
            "       352           0.6946           33.41m\n",
            "       353           0.6945           33.35m\n",
            "       354           0.6943           33.30m\n",
            "       355           0.6941           33.24m\n",
            "       356           0.6940           33.19m\n",
            "       357           0.6938           33.13m\n",
            "       358           0.6936           33.08m\n",
            "       359           0.6934           33.02m\n",
            "       360           0.6933           32.97m\n",
            "       361           0.6931           32.92m\n",
            "       362           0.6929           32.86m\n",
            "       363           0.6928           32.81m\n",
            "       364           0.6926           32.75m\n",
            "       365           0.6924           32.70m\n",
            "       366           0.6922           32.64m\n",
            "       367           0.6921           32.59m\n",
            "       368           0.6918           32.54m\n",
            "       369           0.6917           32.48m\n",
            "       370           0.6915           32.43m\n",
            "       371           0.6913           32.37m\n",
            "       372           0.6912           32.32m\n",
            "       373           0.6911           32.27m\n",
            "       374           0.6909           32.22m\n",
            "       375           0.6908           32.16m\n",
            "       376           0.6906           32.10m\n",
            "       377           0.6904           32.05m\n",
            "       378           0.6902           32.00m\n",
            "       379           0.6900           31.94m\n",
            "       380           0.6899           31.89m\n",
            "       381           0.6898           31.83m\n",
            "       382           0.6896           31.78m\n",
            "       383           0.6895           31.72m\n",
            "       384           0.6893           31.67m\n",
            "       385           0.6892           31.62m\n",
            "       386           0.6891           31.57m\n",
            "       387           0.6889           31.51m\n",
            "       388           0.6887           31.47m\n",
            "       389           0.6885           31.41m\n",
            "       390           0.6884           31.36m\n",
            "       391           0.6882           31.31m\n",
            "       392           0.6881           31.26m\n",
            "       393           0.6878           31.21m\n",
            "       394           0.6877           31.15m\n",
            "       395           0.6875           31.10m\n",
            "       396           0.6873           31.05m\n",
            "       397           0.6872           31.00m\n",
            "       398           0.6871           30.95m\n",
            "       399           0.6870           30.89m\n",
            "       400           0.6868           30.84m\n",
            "       401           0.6867           30.79m\n",
            "       402           0.6866           30.75m\n",
            "       403           0.6865           30.70m\n",
            "       404           0.6863           30.65m\n",
            "       405           0.6862           30.60m\n",
            "       406           0.6861           30.54m\n",
            "       407           0.6860           30.49m\n",
            "       408           0.6859           30.43m\n",
            "       409           0.6857           30.38m\n",
            "       410           0.6856           30.33m\n",
            "       411           0.6854           30.27m\n",
            "       412           0.6853           30.23m\n",
            "       413           0.6852           30.17m\n",
            "       414           0.6850           30.12m\n",
            "       415           0.6849           30.07m\n",
            "       416           0.6848           30.02m\n",
            "       417           0.6846           29.97m\n",
            "       418           0.6845           29.92m\n",
            "       419           0.6843           29.87m\n",
            "       420           0.6842           29.81m\n",
            "       421           0.6840           29.77m\n",
            "       422           0.6839           29.72m\n",
            "       423           0.6837           29.66m\n",
            "       424           0.6836           29.61m\n",
            "       425           0.6835           29.56m\n",
            "       426           0.6834           29.50m\n",
            "       427           0.6833           29.45m\n",
            "       428           0.6831           29.40m\n",
            "       429           0.6830           29.35m\n",
            "       430           0.6828           29.30m\n",
            "       431           0.6827           29.25m\n",
            "       432           0.6826           29.20m\n",
            "       433           0.6825           29.15m\n",
            "       434           0.6823           29.10m\n",
            "       435           0.6822           29.05m\n",
            "       436           0.6820           29.01m\n",
            "       437           0.6818           28.96m\n",
            "       438           0.6817           28.90m\n",
            "       439           0.6816           28.85m\n",
            "       440           0.6815           28.80m\n",
            "       441           0.6814           28.74m\n",
            "       442           0.6813           28.69m\n",
            "       443           0.6811           28.64m\n",
            "       444           0.6810           28.59m\n",
            "       445           0.6809           28.53m\n",
            "       446           0.6808           28.48m\n",
            "       447           0.6807           28.43m\n",
            "       448           0.6806           28.38m\n",
            "       449           0.6804           28.33m\n",
            "       450           0.6803           28.27m\n",
            "       451           0.6801           28.22m\n",
            "       452           0.6800           28.17m\n",
            "       453           0.6799           28.12m\n",
            "       454           0.6798           28.06m\n",
            "       455           0.6796           28.01m\n",
            "       456           0.6795           27.96m\n",
            "       457           0.6794           27.91m\n",
            "       458           0.6793           27.85m\n",
            "       459           0.6792           27.80m\n",
            "       460           0.6791           27.75m\n",
            "       461           0.6789           27.70m\n",
            "       462           0.6789           27.64m\n",
            "       463           0.6787           27.59m\n",
            "       464           0.6786           27.54m\n",
            "       465           0.6784           27.49m\n",
            "       466           0.6784           27.43m\n",
            "       467           0.6782           27.38m\n",
            "       468           0.6780           27.33m\n",
            "       469           0.6779           27.28m\n",
            "       470           0.6777           27.22m\n",
            "       471           0.6776           27.17m\n",
            "       472           0.6774           27.12m\n",
            "       473           0.6773           27.07m\n",
            "       474           0.6772           27.01m\n",
            "       475           0.6771           26.96m\n",
            "       476           0.6770           26.91m\n",
            "       477           0.6768           26.86m\n",
            "       478           0.6767           26.81m\n",
            "       479           0.6765           26.75m\n",
            "       480           0.6764           26.70m\n",
            "       481           0.6763           26.65m\n",
            "       482           0.6761           26.60m\n",
            "       483           0.6760           26.55m\n",
            "       484           0.6759           26.49m\n",
            "       485           0.6758           26.44m\n",
            "       486           0.6757           26.39m\n",
            "       487           0.6756           26.34m\n",
            "       488           0.6755           26.28m\n",
            "       489           0.6753           26.23m\n",
            "       490           0.6752           26.18m\n",
            "       491           0.6751           26.13m\n",
            "       492           0.6750           26.07m\n",
            "       493           0.6749           26.02m\n",
            "       494           0.6747           25.97m\n",
            "       495           0.6746           25.92m\n",
            "       496           0.6745           25.87m\n",
            "       497           0.6743           25.81m\n",
            "       498           0.6742           25.76m\n",
            "       499           0.6741           25.71m\n",
            "       500           0.6740           25.66m\n",
            "       501           0.6739           25.60m\n",
            "       502           0.6738           25.55m\n",
            "       503           0.6737           25.51m\n",
            "       504           0.6736           25.46m\n",
            "       505           0.6734           25.41m\n",
            "       506           0.6733           25.35m\n",
            "       507           0.6732           25.30m\n",
            "       508           0.6732           25.25m\n",
            "       509           0.6730           25.20m\n",
            "       510           0.6729           25.14m\n",
            "       511           0.6728           25.09m\n",
            "       512           0.6727           25.04m\n",
            "       513           0.6726           24.99m\n",
            "       514           0.6724           24.93m\n",
            "       515           0.6723           24.88m\n",
            "       516           0.6722           24.83m\n",
            "       517           0.6721           24.78m\n",
            "       518           0.6719           24.73m\n",
            "       519           0.6718           24.67m\n",
            "       520           0.6717           24.62m\n",
            "       521           0.6717           24.57m\n",
            "       522           0.6716           24.51m\n",
            "       523           0.6715           24.46m\n",
            "       524           0.6714           24.41m\n",
            "       525           0.6712           24.36m\n",
            "       526           0.6710           24.30m\n",
            "       527           0.6709           24.25m\n",
            "       528           0.6707           24.20m\n",
            "       529           0.6706           24.14m\n",
            "       530           0.6705           24.09m\n",
            "       531           0.6704           24.04m\n",
            "       532           0.6703           23.99m\n",
            "       533           0.6702           23.93m\n",
            "       534           0.6700           23.88m\n",
            "       535           0.6699           23.83m\n",
            "       536           0.6698           23.78m\n",
            "       537           0.6697           23.73m\n",
            "       538           0.6696           23.68m\n",
            "       539           0.6695           23.63m\n",
            "       540           0.6694           23.58m\n",
            "       541           0.6693           23.54m\n",
            "       542           0.6692           23.49m\n",
            "       543           0.6691           23.43m\n",
            "       544           0.6690           23.38m\n",
            "       545           0.6689           23.33m\n",
            "       546           0.6688           23.28m\n",
            "       547           0.6687           23.23m\n",
            "       548           0.6686           23.18m\n",
            "       549           0.6685           23.12m\n",
            "       550           0.6685           23.07m\n",
            "       551           0.6683           23.02m\n",
            "       552           0.6682           22.97m\n",
            "       553           0.6682           22.92m\n",
            "       554           0.6681           22.86m\n",
            "       555           0.6679           22.81m\n",
            "       556           0.6678           22.76m\n",
            "       557           0.6677           22.71m\n",
            "       558           0.6676           22.66m\n",
            "       559           0.6675           22.61m\n",
            "       560           0.6674           22.55m\n",
            "       561           0.6673           22.50m\n",
            "       562           0.6672           22.45m\n",
            "       563           0.6671           22.40m\n",
            "       564           0.6669           22.35m\n",
            "       565           0.6668           22.30m\n",
            "       566           0.6667           22.24m\n",
            "       567           0.6666           22.19m\n",
            "       568           0.6665           22.14m\n",
            "       569           0.6664           22.09m\n",
            "       570           0.6663           22.04m\n",
            "       571           0.6662           21.98m\n",
            "       572           0.6661           21.93m\n",
            "       573           0.6660           21.88m\n",
            "       574           0.6658           21.83m\n",
            "       575           0.6657           21.78m\n",
            "       576           0.6656           21.73m\n",
            "       577           0.6655           21.67m\n",
            "       578           0.6654           21.62m\n",
            "       579           0.6653           21.57m\n",
            "       580           0.6652           21.52m\n",
            "       581           0.6651           21.47m\n",
            "       582           0.6650           21.41m\n",
            "       583           0.6648           21.36m\n",
            "       584           0.6647           21.31m\n",
            "       585           0.6646           21.26m\n",
            "       586           0.6644           21.21m\n",
            "       587           0.6643           21.16m\n",
            "       588           0.6642           21.10m\n",
            "       589           0.6641           21.05m\n",
            "       590           0.6640           21.00m\n",
            "       591           0.6638           20.95m\n",
            "       592           0.6637           20.90m\n",
            "       593           0.6636           20.84m\n",
            "       594           0.6634           20.79m\n",
            "       595           0.6633           20.74m\n",
            "       596           0.6632           20.69m\n",
            "       597           0.6631           20.64m\n",
            "       598           0.6630           20.59m\n",
            "       599           0.6629           20.53m\n",
            "       600           0.6628           20.48m\n",
            "       601           0.6627           20.43m\n",
            "       602           0.6626           20.38m\n",
            "       603           0.6625           20.33m\n",
            "       604           0.6624           20.28m\n",
            "       605           0.6623           20.24m\n",
            "       606           0.6622           20.18m\n",
            "       607           0.6621           20.13m\n",
            "       608           0.6620           20.08m\n",
            "       609           0.6619           20.03m\n",
            "       610           0.6618           19.98m\n",
            "       611           0.6617           19.93m\n",
            "       612           0.6616           19.88m\n",
            "       613           0.6615           19.83m\n",
            "       614           0.6614           19.78m\n",
            "       615           0.6613           19.73m\n",
            "       616           0.6612           19.68m\n",
            "       617           0.6611           19.63m\n",
            "       618           0.6610           19.58m\n",
            "       619           0.6609           19.53m\n",
            "       620           0.6608           19.48m\n",
            "       621           0.6607           19.43m\n",
            "       622           0.6606           19.38m\n",
            "       623           0.6605           19.33m\n",
            "       624           0.6604           19.28m\n",
            "       625           0.6603           19.23m\n",
            "       626           0.6602           19.18m\n",
            "       627           0.6601           19.13m\n",
            "       628           0.6600           19.08m\n",
            "       629           0.6598           19.03m\n",
            "       630           0.6597           18.98m\n",
            "       631           0.6596           18.93m\n",
            "       632           0.6596           18.88m\n",
            "       633           0.6594           18.83m\n",
            "       634           0.6592           18.77m\n",
            "       635           0.6591           18.72m\n",
            "       636           0.6591           18.67m\n",
            "       637           0.6590           18.62m\n",
            "       638           0.6588           18.57m\n",
            "       639           0.6587           18.52m\n",
            "       640           0.6586           18.47m\n",
            "       641           0.6585           18.42m\n",
            "       642           0.6584           18.38m\n",
            "       643           0.6583           18.33m\n",
            "       644           0.6582           18.28m\n",
            "       645           0.6581           18.23m\n",
            "       646           0.6580           18.19m\n",
            "       647           0.6579           18.14m\n",
            "       648           0.6578           18.09m\n",
            "       649           0.6576           18.03m\n",
            "       650           0.6576           17.98m\n",
            "       651           0.6575           17.93m\n",
            "       652           0.6574           17.88m\n",
            "       653           0.6573           17.83m\n",
            "       654           0.6572           17.78m\n",
            "       655           0.6571           17.73m\n",
            "       656           0.6570           17.68m\n",
            "       657           0.6568           17.63m\n",
            "       658           0.6567           17.58m\n",
            "       659           0.6566           17.52m\n",
            "       660           0.6565           17.47m\n",
            "       661           0.6564           17.42m\n",
            "       662           0.6563           17.37m\n",
            "       663           0.6563           17.32m\n",
            "       664           0.6561           17.27m\n",
            "       665           0.6560           17.22m\n",
            "       666           0.6559           17.16m\n",
            "       667           0.6558           17.11m\n",
            "       668           0.6557           17.06m\n",
            "       669           0.6556           17.01m\n",
            "       670           0.6555           16.96m\n",
            "       671           0.6554           16.90m\n",
            "       672           0.6553           16.85m\n",
            "       673           0.6552           16.80m\n",
            "       674           0.6551           16.75m\n",
            "       675           0.6550           16.70m\n",
            "       676           0.6549           16.65m\n",
            "       677           0.6548           16.59m\n",
            "       678           0.6547           16.54m\n",
            "       679           0.6546           16.49m\n",
            "       680           0.6545           16.44m\n",
            "       681           0.6544           16.39m\n",
            "       682           0.6544           16.34m\n",
            "       683           0.6542           16.28m\n",
            "       684           0.6541           16.23m\n",
            "       685           0.6540           16.18m\n",
            "       686           0.6539           16.13m\n",
            "       687           0.6538           16.08m\n",
            "       688           0.6537           16.03m\n",
            "       689           0.6536           15.97m\n",
            "       690           0.6535           15.92m\n",
            "       691           0.6534           15.87m\n",
            "       692           0.6533           15.82m\n",
            "       693           0.6532           15.77m\n",
            "       694           0.6531           15.72m\n",
            "       695           0.6530           15.66m\n",
            "       696           0.6528           15.61m\n",
            "       697           0.6527           15.56m\n",
            "       698           0.6526           15.51m\n",
            "       699           0.6525           15.46m\n",
            "       700           0.6525           15.41m\n",
            "       701           0.6524           15.36m\n",
            "       702           0.6523           15.30m\n",
            "       703           0.6522           15.26m\n",
            "       704           0.6522           15.21m\n",
            "       705           0.6521           15.16m\n",
            "       706           0.6520           15.11m\n",
            "       707           0.6519           15.05m\n",
            "       708           0.6518           15.00m\n",
            "       709           0.6517           14.95m\n",
            "       710           0.6517           14.90m\n",
            "       711           0.6515           14.85m\n",
            "       712           0.6514           14.80m\n",
            "       713           0.6513           14.74m\n",
            "       714           0.6512           14.69m\n",
            "       715           0.6511           14.64m\n",
            "       716           0.6510           14.59m\n",
            "       717           0.6509           14.54m\n",
            "       718           0.6508           14.49m\n",
            "       719           0.6507           14.44m\n",
            "       720           0.6506           14.38m\n",
            "       721           0.6505           14.33m\n",
            "       722           0.6504           14.28m\n",
            "       723           0.6504           14.23m\n",
            "       724           0.6503           14.18m\n",
            "       725           0.6503           14.12m\n",
            "       726           0.6502           14.07m\n",
            "       727           0.6501           14.02m\n",
            "       728           0.6500           13.97m\n",
            "       729           0.6499           13.92m\n",
            "       730           0.6498           13.87m\n",
            "       731           0.6497           13.81m\n",
            "       732           0.6496           13.76m\n",
            "       733           0.6495           13.71m\n",
            "       734           0.6494           13.66m\n",
            "       735           0.6493           13.61m\n",
            "       736           0.6493           13.56m\n",
            "       737           0.6492           13.50m\n",
            "       738           0.6491           13.45m\n",
            "       739           0.6490           13.40m\n",
            "       740           0.6489           13.35m\n",
            "       741           0.6488           13.30m\n",
            "       742           0.6487           13.24m\n",
            "       743           0.6486           13.19m\n",
            "       744           0.6485           13.14m\n",
            "       745           0.6484           13.09m\n",
            "       746           0.6483           13.04m\n",
            "       747           0.6482           12.99m\n",
            "       748           0.6481           12.94m\n",
            "       749           0.6480           12.89m\n",
            "       750           0.6479           12.84m\n",
            "       751           0.6478           12.78m\n",
            "       752           0.6477           12.73m\n",
            "       753           0.6476           12.68m\n",
            "       754           0.6475           12.63m\n",
            "       755           0.6474           12.58m\n",
            "       756           0.6474           12.53m\n",
            "       757           0.6473           12.48m\n",
            "       758           0.6472           12.42m\n",
            "       759           0.6471           12.37m\n",
            "       760           0.6470           12.32m\n",
            "       761           0.6469           12.27m\n",
            "       762           0.6468           12.22m\n",
            "       763           0.6467           12.17m\n",
            "       764           0.6466           12.12m\n",
            "       765           0.6466           12.06m\n",
            "       766           0.6465           12.01m\n",
            "       767           0.6464           11.96m\n",
            "       768           0.6463           11.91m\n",
            "       769           0.6461           11.86m\n",
            "       770           0.6460           11.81m\n",
            "       771           0.6459           11.76m\n",
            "       772           0.6458           11.71m\n",
            "       773           0.6457           11.66m\n",
            "       774           0.6456           11.60m\n",
            "       775           0.6456           11.55m\n",
            "       776           0.6455           11.50m\n",
            "       777           0.6454           11.45m\n",
            "       778           0.6453           11.40m\n",
            "       779           0.6452           11.35m\n",
            "       780           0.6451           11.30m\n",
            "       781           0.6450           11.25m\n",
            "       782           0.6449           11.20m\n",
            "       783           0.6448           11.14m\n",
            "       784           0.6447           11.09m\n",
            "       785           0.6447           11.04m\n",
            "       786           0.6446           10.99m\n",
            "       787           0.6445           10.94m\n",
            "       788           0.6445           10.89m\n",
            "       789           0.6443           10.84m\n",
            "       790           0.6443           10.78m\n",
            "       791           0.6441           10.73m\n",
            "       792           0.6440           10.68m\n",
            "       793           0.6440           10.63m\n",
            "       794           0.6439           10.58m\n",
            "       795           0.6438           10.53m\n",
            "       796           0.6437           10.48m\n",
            "       797           0.6436           10.42m\n",
            "       798           0.6436           10.37m\n",
            "       799           0.6435           10.32m\n",
            "       800           0.6434           10.27m\n",
            "       801           0.6434           10.22m\n",
            "       802           0.6433           10.17m\n",
            "       803           0.6432           10.12m\n",
            "       804           0.6431           10.07m\n",
            "       805           0.6430           10.02m\n",
            "       806           0.6429            9.97m\n",
            "       807           0.6429            9.92m\n",
            "       808           0.6428            9.86m\n",
            "       809           0.6427            9.81m\n",
            "       810           0.6426            9.76m\n",
            "       811           0.6425            9.71m\n",
            "       812           0.6424            9.66m\n",
            "       813           0.6424            9.61m\n",
            "       814           0.6423            9.56m\n",
            "       815           0.6422            9.51m\n",
            "       816           0.6421            9.45m\n",
            "       817           0.6420            9.40m\n",
            "       818           0.6420            9.35m\n",
            "       819           0.6418            9.30m\n",
            "       820           0.6418            9.25m\n",
            "       821           0.6417            9.20m\n",
            "       822           0.6416            9.15m\n",
            "       823           0.6415            9.10m\n",
            "       824           0.6414            9.04m\n",
            "       825           0.6414            8.99m\n",
            "       826           0.6413            8.94m\n",
            "       827           0.6412            8.89m\n",
            "       828           0.6411            8.84m\n",
            "       829           0.6410            8.79m\n",
            "       830           0.6410            8.74m\n",
            "       831           0.6409            8.68m\n",
            "       832           0.6408            8.63m\n",
            "       833           0.6407            8.58m\n",
            "       834           0.6406            8.53m\n",
            "       835           0.6405            8.48m\n",
            "       836           0.6404            8.43m\n",
            "       837           0.6403            8.38m\n",
            "       838           0.6403            8.32m\n",
            "       839           0.6402            8.27m\n",
            "       840           0.6401            8.22m\n",
            "       841           0.6400            8.17m\n",
            "       842           0.6399            8.12m\n",
            "       843           0.6398            8.07m\n",
            "       844           0.6397            8.02m\n",
            "       845           0.6397            7.97m\n",
            "       846           0.6395            7.91m\n",
            "       847           0.6394            7.86m\n",
            "       848           0.6393            7.81m\n",
            "       849           0.6393            7.76m\n",
            "       850           0.6392            7.71m\n",
            "       851           0.6391            7.66m\n",
            "       852           0.6390            7.61m\n",
            "       853           0.6389            7.56m\n",
            "       854           0.6388            7.51m\n",
            "       855           0.6387            7.46m\n",
            "       856           0.6386            7.41m\n",
            "       857           0.6385            7.35m\n",
            "       858           0.6384            7.30m\n",
            "       859           0.6383            7.25m\n",
            "       860           0.6383            7.20m\n",
            "       861           0.6382            7.15m\n",
            "       862           0.6381            7.10m\n",
            "       863           0.6380            7.05m\n",
            "       864           0.6379            7.00m\n",
            "       865           0.6378            6.94m\n",
            "       866           0.6378            6.89m\n",
            "       867           0.6377            6.84m\n",
            "       868           0.6376            6.79m\n",
            "       869           0.6376            6.74m\n",
            "       870           0.6375            6.69m\n",
            "       871           0.6374            6.64m\n",
            "       872           0.6373            6.58m\n",
            "       873           0.6373            6.53m\n",
            "       874           0.6372            6.48m\n",
            "       875           0.6371            6.43m\n",
            "       876           0.6370            6.38m\n",
            "       877           0.6369            6.33m\n",
            "       878           0.6368            6.28m\n",
            "       879           0.6367            6.23m\n",
            "       880           0.6366            6.17m\n",
            "       881           0.6366            6.12m\n",
            "       882           0.6365            6.07m\n",
            "       883           0.6364            6.02m\n",
            "       884           0.6363            5.97m\n",
            "       885           0.6362            5.92m\n",
            "       886           0.6361            5.87m\n",
            "       887           0.6361            5.82m\n",
            "       888           0.6360            5.76m\n",
            "       889           0.6359            5.71m\n",
            "       890           0.6358            5.66m\n",
            "       891           0.6357            5.61m\n",
            "       892           0.6356            5.56m\n",
            "       893           0.6355            5.51m\n",
            "       894           0.6354            5.46m\n",
            "       895           0.6354            5.41m\n",
            "       896           0.6353            5.35m\n",
            "       897           0.6352            5.30m\n",
            "       898           0.6352            5.25m\n",
            "       899           0.6351            5.20m\n",
            "       900           0.6351            5.15m\n",
            "       901           0.6350            5.10m\n",
            "       902           0.6348            5.05m\n",
            "       903           0.6348            5.00m\n",
            "       904           0.6347            4.94m\n",
            "       905           0.6346            4.89m\n",
            "       906           0.6345            4.84m\n",
            "       907           0.6344            4.79m\n",
            "       908           0.6344            4.74m\n",
            "       909           0.6342            4.69m\n",
            "       910           0.6342            4.64m\n",
            "       911           0.6341            4.58m\n",
            "       912           0.6340            4.53m\n",
            "       913           0.6339            4.48m\n",
            "       914           0.6339            4.43m\n",
            "       915           0.6338            4.38m\n",
            "       916           0.6337            4.33m\n",
            "       917           0.6336            4.28m\n",
            "       918           0.6336            4.22m\n",
            "       919           0.6335            4.17m\n",
            "       920           0.6333            4.12m\n",
            "       921           0.6332            4.07m\n",
            "       922           0.6331            4.02m\n",
            "       923           0.6331            3.97m\n",
            "       924           0.6330            3.91m\n",
            "       925           0.6329            3.86m\n",
            "       926           0.6329            3.81m\n",
            "       927           0.6328            3.76m\n",
            "       928           0.6327            3.71m\n",
            "       929           0.6327            3.66m\n",
            "       930           0.6326            3.61m\n",
            "       931           0.6325            3.55m\n",
            "       932           0.6324            3.50m\n",
            "       933           0.6324            3.45m\n",
            "       934           0.6323            3.40m\n",
            "       935           0.6322            3.35m\n",
            "       936           0.6321            3.30m\n",
            "       937           0.6320            3.25m\n",
            "       938           0.6320            3.19m\n",
            "       939           0.6319            3.14m\n",
            "       940           0.6318            3.09m\n",
            "       941           0.6317            3.04m\n",
            "       942           0.6316            2.99m\n",
            "       943           0.6316            2.94m\n",
            "       944           0.6315            2.88m\n",
            "       945           0.6314            2.83m\n",
            "       946           0.6314            2.78m\n",
            "       947           0.6313            2.73m\n",
            "       948           0.6312            2.68m\n",
            "       949           0.6311            2.63m\n",
            "       950           0.6311            2.58m\n",
            "       951           0.6310            2.52m\n",
            "       952           0.6309            2.47m\n",
            "       953           0.6308            2.42m\n",
            "       954           0.6307            2.37m\n",
            "       955           0.6306            2.32m\n",
            "       956           0.6305            2.27m\n",
            "       957           0.6305            2.22m\n",
            "       958           0.6304            2.16m\n",
            "       959           0.6303            2.11m\n",
            "       960           0.6302            2.06m\n",
            "       961           0.6301            2.01m\n",
            "       962           0.6300            1.96m\n",
            "       963           0.6300            1.91m\n",
            "       964           0.6299            1.86m\n",
            "       965           0.6299            1.80m\n",
            "       966           0.6298            1.75m\n",
            "       967           0.6297            1.70m\n",
            "       968           0.6297            1.65m\n",
            "       969           0.6296            1.60m\n",
            "       970           0.6295            1.55m\n",
            "       971           0.6294            1.49m\n",
            "       972           0.6293            1.44m\n",
            "       973           0.6292            1.39m\n",
            "       974           0.6292            1.34m\n",
            "       975           0.6291            1.29m\n",
            "       976           0.6290            1.24m\n",
            "       977           0.6290            1.19m\n",
            "       978           0.6289            1.13m\n",
            "       979           0.6288            1.08m\n",
            "       980           0.6287            1.03m\n",
            "       981           0.6286           58.74s\n",
            "       982           0.6286           55.65s\n",
            "       983           0.6285           52.56s\n",
            "       984           0.6284           49.47s\n",
            "       985           0.6283           46.38s\n",
            "       986           0.6282           43.28s\n",
            "       987           0.6281           40.19s\n",
            "       988           0.6281           37.10s\n",
            "       989           0.6280           34.01s\n",
            "       990           0.6279           30.92s\n",
            "       991           0.6278           27.82s\n",
            "       992           0.6278           24.73s\n",
            "       993           0.6277           21.64s\n",
            "       994           0.6277           18.55s\n",
            "       995           0.6276           15.46s\n",
            "       996           0.6275           12.37s\n",
            "       997           0.6274            9.27s\n",
            "       998           0.6273            6.18s\n",
            "       999           0.6273            3.09s\n",
            "      1000           0.6272            0.00s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=5,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=None, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=2,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VslxQQHEQ0v0",
        "outputId": "62e4dda7-53b5-4dbb-e286-a6b3107f34b8"
      },
      "source": [
        "gbc_perf = roc_auc_score(y_test, gbc.predict(X_test))\n",
        "gbc_perf"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7191541046359547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKBael0Mr-CO"
      },
      "source": [
        "## XGBoost "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUwIGZ6cRGDk",
        "outputId": "42e6ab80-14ec-4acd-b7d5-88a79c7b8f4d"
      },
      "source": [
        "from datetime import datetime\n",
        "print('Initializing xgboost.sklearn.XGBClassifier and starting training...')\n",
        "\n",
        "st = datetime.now()\n",
        "\n",
        "clf = xgboost.sklearn.XGBClassifier(\n",
        "    objective=\"binary:logistic\", \n",
        "    learning_rate=0.05, \n",
        "    seed=9616, \n",
        "    max_depth=20, \n",
        "    gamma=10, \n",
        "    n_estimators=500)\n",
        "\n",
        "clf.fit(X_train, y_train, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=eval_set, verbose=True)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing xgboost.sklearn.XGBClassifier and starting training...\n",
            "[0]\tvalidation_0-auc:0.797739\n",
            "Will train until validation_0-auc hasn't improved in 20 rounds.\n",
            "[1]\tvalidation_0-auc:0.803201\n",
            "[2]\tvalidation_0-auc:0.806008\n",
            "[3]\tvalidation_0-auc:0.808736\n",
            "[4]\tvalidation_0-auc:0.810664\n",
            "[5]\tvalidation_0-auc:0.812989\n",
            "[6]\tvalidation_0-auc:0.813518\n",
            "[7]\tvalidation_0-auc:0.814749\n",
            "[8]\tvalidation_0-auc:0.816762\n",
            "[9]\tvalidation_0-auc:0.818446\n",
            "[10]\tvalidation_0-auc:0.819051\n",
            "[11]\tvalidation_0-auc:0.819937\n",
            "[12]\tvalidation_0-auc:0.820884\n",
            "[13]\tvalidation_0-auc:0.821352\n",
            "[14]\tvalidation_0-auc:0.822292\n",
            "[15]\tvalidation_0-auc:0.82284\n",
            "[16]\tvalidation_0-auc:0.823493\n",
            "[17]\tvalidation_0-auc:0.824134\n",
            "[18]\tvalidation_0-auc:0.824683\n",
            "[19]\tvalidation_0-auc:0.825136\n",
            "[20]\tvalidation_0-auc:0.825666\n",
            "[21]\tvalidation_0-auc:0.826102\n",
            "[22]\tvalidation_0-auc:0.82654\n",
            "[23]\tvalidation_0-auc:0.826873\n",
            "[24]\tvalidation_0-auc:0.827673\n",
            "[25]\tvalidation_0-auc:0.828058\n",
            "[26]\tvalidation_0-auc:0.82826\n",
            "[27]\tvalidation_0-auc:0.828736\n",
            "[28]\tvalidation_0-auc:0.829069\n",
            "[29]\tvalidation_0-auc:0.829468\n",
            "[30]\tvalidation_0-auc:0.829761\n",
            "[31]\tvalidation_0-auc:0.830321\n",
            "[32]\tvalidation_0-auc:0.830664\n",
            "[33]\tvalidation_0-auc:0.830905\n",
            "[34]\tvalidation_0-auc:0.831297\n",
            "[35]\tvalidation_0-auc:0.831641\n",
            "[36]\tvalidation_0-auc:0.83208\n",
            "[37]\tvalidation_0-auc:0.832321\n",
            "[38]\tvalidation_0-auc:0.832762\n",
            "[39]\tvalidation_0-auc:0.832949\n",
            "[40]\tvalidation_0-auc:0.833403\n",
            "[41]\tvalidation_0-auc:0.833975\n",
            "[42]\tvalidation_0-auc:0.834515\n",
            "[43]\tvalidation_0-auc:0.834914\n",
            "[44]\tvalidation_0-auc:0.835181\n",
            "[45]\tvalidation_0-auc:0.835464\n",
            "[46]\tvalidation_0-auc:0.83589\n",
            "[47]\tvalidation_0-auc:0.836576\n",
            "[48]\tvalidation_0-auc:0.836908\n",
            "[49]\tvalidation_0-auc:0.837926\n",
            "[50]\tvalidation_0-auc:0.8383\n",
            "[51]\tvalidation_0-auc:0.838797\n",
            "[52]\tvalidation_0-auc:0.83921\n",
            "[53]\tvalidation_0-auc:0.839373\n",
            "[54]\tvalidation_0-auc:0.839872\n",
            "[55]\tvalidation_0-auc:0.84006\n",
            "[56]\tvalidation_0-auc:0.840388\n",
            "[57]\tvalidation_0-auc:0.840627\n",
            "[58]\tvalidation_0-auc:0.840951\n",
            "[59]\tvalidation_0-auc:0.841064\n",
            "[60]\tvalidation_0-auc:0.842064\n",
            "[61]\tvalidation_0-auc:0.842233\n",
            "[62]\tvalidation_0-auc:0.843151\n",
            "[63]\tvalidation_0-auc:0.843936\n",
            "[64]\tvalidation_0-auc:0.844139\n",
            "[65]\tvalidation_0-auc:0.844911\n",
            "[66]\tvalidation_0-auc:0.845099\n",
            "[67]\tvalidation_0-auc:0.845459\n",
            "[68]\tvalidation_0-auc:0.845575\n",
            "[69]\tvalidation_0-auc:0.846435\n",
            "[70]\tvalidation_0-auc:0.846624\n",
            "[71]\tvalidation_0-auc:0.846936\n",
            "[72]\tvalidation_0-auc:0.847091\n",
            "[73]\tvalidation_0-auc:0.847248\n",
            "[74]\tvalidation_0-auc:0.847436\n",
            "[75]\tvalidation_0-auc:0.848245\n",
            "[76]\tvalidation_0-auc:0.848415\n",
            "[77]\tvalidation_0-auc:0.848548\n",
            "[78]\tvalidation_0-auc:0.848776\n",
            "[79]\tvalidation_0-auc:0.848878\n",
            "[80]\tvalidation_0-auc:0.849417\n",
            "[81]\tvalidation_0-auc:0.849575\n",
            "[82]\tvalidation_0-auc:0.849908\n",
            "[83]\tvalidation_0-auc:0.850035\n",
            "[84]\tvalidation_0-auc:0.850183\n",
            "[85]\tvalidation_0-auc:0.850737\n",
            "[86]\tvalidation_0-auc:0.85087\n",
            "[87]\tvalidation_0-auc:0.851512\n",
            "[88]\tvalidation_0-auc:0.852046\n",
            "[89]\tvalidation_0-auc:0.852209\n",
            "[90]\tvalidation_0-auc:0.852311\n",
            "[91]\tvalidation_0-auc:0.852459\n",
            "[92]\tvalidation_0-auc:0.852857\n",
            "[93]\tvalidation_0-auc:0.853023\n",
            "[94]\tvalidation_0-auc:0.853233\n",
            "[95]\tvalidation_0-auc:0.853313\n",
            "[96]\tvalidation_0-auc:0.853817\n",
            "[97]\tvalidation_0-auc:0.854108\n",
            "[98]\tvalidation_0-auc:0.854193\n",
            "[99]\tvalidation_0-auc:0.854364\n",
            "[100]\tvalidation_0-auc:0.854562\n",
            "[101]\tvalidation_0-auc:0.855108\n",
            "[102]\tvalidation_0-auc:0.855188\n",
            "[103]\tvalidation_0-auc:0.855395\n",
            "[104]\tvalidation_0-auc:0.855526\n",
            "[105]\tvalidation_0-auc:0.855757\n",
            "[106]\tvalidation_0-auc:0.856078\n",
            "[107]\tvalidation_0-auc:0.856227\n",
            "[108]\tvalidation_0-auc:0.856391\n",
            "[109]\tvalidation_0-auc:0.856688\n",
            "[110]\tvalidation_0-auc:0.856827\n",
            "[111]\tvalidation_0-auc:0.857035\n",
            "[112]\tvalidation_0-auc:0.857337\n",
            "[113]\tvalidation_0-auc:0.85774\n",
            "[114]\tvalidation_0-auc:0.85787\n",
            "[115]\tvalidation_0-auc:0.858382\n",
            "[116]\tvalidation_0-auc:0.85844\n",
            "[117]\tvalidation_0-auc:0.85851\n",
            "[118]\tvalidation_0-auc:0.858676\n",
            "[119]\tvalidation_0-auc:0.858772\n",
            "[120]\tvalidation_0-auc:0.85889\n",
            "[121]\tvalidation_0-auc:0.858993\n",
            "[122]\tvalidation_0-auc:0.85924\n",
            "[123]\tvalidation_0-auc:0.859567\n",
            "[124]\tvalidation_0-auc:0.859831\n",
            "[125]\tvalidation_0-auc:0.859894\n",
            "[126]\tvalidation_0-auc:0.860058\n",
            "[127]\tvalidation_0-auc:0.86017\n",
            "[128]\tvalidation_0-auc:0.86049\n",
            "[129]\tvalidation_0-auc:0.860617\n",
            "[130]\tvalidation_0-auc:0.86076\n",
            "[131]\tvalidation_0-auc:0.860931\n",
            "[132]\tvalidation_0-auc:0.861138\n",
            "[133]\tvalidation_0-auc:0.86121\n",
            "[134]\tvalidation_0-auc:0.861254\n",
            "[135]\tvalidation_0-auc:0.861334\n",
            "[136]\tvalidation_0-auc:0.861464\n",
            "[137]\tvalidation_0-auc:0.861598\n",
            "[138]\tvalidation_0-auc:0.862034\n",
            "[139]\tvalidation_0-auc:0.862254\n",
            "[140]\tvalidation_0-auc:0.862291\n",
            "[141]\tvalidation_0-auc:0.86249\n",
            "[142]\tvalidation_0-auc:0.862705\n",
            "[143]\tvalidation_0-auc:0.863002\n",
            "[144]\tvalidation_0-auc:0.863077\n",
            "[145]\tvalidation_0-auc:0.863158\n",
            "[146]\tvalidation_0-auc:0.863475\n",
            "[147]\tvalidation_0-auc:0.863776\n",
            "[148]\tvalidation_0-auc:0.863885\n",
            "[149]\tvalidation_0-auc:0.864044\n",
            "[150]\tvalidation_0-auc:0.86418\n",
            "[151]\tvalidation_0-auc:0.864278\n",
            "[152]\tvalidation_0-auc:0.864534\n",
            "[153]\tvalidation_0-auc:0.86459\n",
            "[154]\tvalidation_0-auc:0.864766\n",
            "[155]\tvalidation_0-auc:0.864862\n",
            "[156]\tvalidation_0-auc:0.864998\n",
            "[157]\tvalidation_0-auc:0.865175\n",
            "[158]\tvalidation_0-auc:0.86538\n",
            "[159]\tvalidation_0-auc:0.86547\n",
            "[160]\tvalidation_0-auc:0.865576\n",
            "[161]\tvalidation_0-auc:0.865651\n",
            "[162]\tvalidation_0-auc:0.865765\n",
            "[163]\tvalidation_0-auc:0.865795\n",
            "[164]\tvalidation_0-auc:0.865913\n",
            "[165]\tvalidation_0-auc:0.865953\n",
            "[166]\tvalidation_0-auc:0.865978\n",
            "[167]\tvalidation_0-auc:0.866093\n",
            "[168]\tvalidation_0-auc:0.86617\n",
            "[169]\tvalidation_0-auc:0.866231\n",
            "[170]\tvalidation_0-auc:0.866254\n",
            "[171]\tvalidation_0-auc:0.866432\n",
            "[172]\tvalidation_0-auc:0.866574\n",
            "[173]\tvalidation_0-auc:0.866587\n",
            "[174]\tvalidation_0-auc:0.86661\n",
            "[175]\tvalidation_0-auc:0.866737\n",
            "[176]\tvalidation_0-auc:0.866841\n",
            "[177]\tvalidation_0-auc:0.866854\n",
            "[178]\tvalidation_0-auc:0.866973\n",
            "[179]\tvalidation_0-auc:0.867059\n",
            "[180]\tvalidation_0-auc:0.867257\n",
            "[181]\tvalidation_0-auc:0.867315\n",
            "[182]\tvalidation_0-auc:0.867445\n",
            "[183]\tvalidation_0-auc:0.867507\n",
            "[184]\tvalidation_0-auc:0.867561\n",
            "[185]\tvalidation_0-auc:0.867638\n",
            "[186]\tvalidation_0-auc:0.867683\n",
            "[187]\tvalidation_0-auc:0.86775\n",
            "[188]\tvalidation_0-auc:0.867852\n",
            "[189]\tvalidation_0-auc:0.867927\n",
            "[190]\tvalidation_0-auc:0.867966\n",
            "[191]\tvalidation_0-auc:0.868062\n",
            "[192]\tvalidation_0-auc:0.868171\n",
            "[193]\tvalidation_0-auc:0.868167\n",
            "[194]\tvalidation_0-auc:0.868245\n",
            "[195]\tvalidation_0-auc:0.868267\n",
            "[196]\tvalidation_0-auc:0.868291\n",
            "[197]\tvalidation_0-auc:0.868353\n",
            "[198]\tvalidation_0-auc:0.86838\n",
            "[199]\tvalidation_0-auc:0.868493\n",
            "[200]\tvalidation_0-auc:0.868574\n",
            "[201]\tvalidation_0-auc:0.868643\n",
            "[202]\tvalidation_0-auc:0.868679\n",
            "[203]\tvalidation_0-auc:0.868706\n",
            "[204]\tvalidation_0-auc:0.868738\n",
            "[205]\tvalidation_0-auc:0.868827\n",
            "[206]\tvalidation_0-auc:0.868868\n",
            "[207]\tvalidation_0-auc:0.868916\n",
            "[208]\tvalidation_0-auc:0.868926\n",
            "[209]\tvalidation_0-auc:0.868974\n",
            "[210]\tvalidation_0-auc:0.868996\n",
            "[211]\tvalidation_0-auc:0.869034\n",
            "[212]\tvalidation_0-auc:0.86907\n",
            "[213]\tvalidation_0-auc:0.869146\n",
            "[214]\tvalidation_0-auc:0.869155\n",
            "[215]\tvalidation_0-auc:0.869177\n",
            "[216]\tvalidation_0-auc:0.869226\n",
            "[217]\tvalidation_0-auc:0.869251\n",
            "[218]\tvalidation_0-auc:0.869277\n",
            "[219]\tvalidation_0-auc:0.869379\n",
            "[220]\tvalidation_0-auc:0.869434\n",
            "[221]\tvalidation_0-auc:0.869461\n",
            "[222]\tvalidation_0-auc:0.86956\n",
            "[223]\tvalidation_0-auc:0.869579\n",
            "[224]\tvalidation_0-auc:0.869611\n",
            "[225]\tvalidation_0-auc:0.869684\n",
            "[226]\tvalidation_0-auc:0.869729\n",
            "[227]\tvalidation_0-auc:0.869758\n",
            "[228]\tvalidation_0-auc:0.869822\n",
            "[229]\tvalidation_0-auc:0.869854\n",
            "[230]\tvalidation_0-auc:0.869874\n",
            "[231]\tvalidation_0-auc:0.869965\n",
            "[232]\tvalidation_0-auc:0.869985\n",
            "[233]\tvalidation_0-auc:0.870051\n",
            "[234]\tvalidation_0-auc:0.870108\n",
            "[235]\tvalidation_0-auc:0.870135\n",
            "[236]\tvalidation_0-auc:0.870171\n",
            "[237]\tvalidation_0-auc:0.870217\n",
            "[238]\tvalidation_0-auc:0.870243\n",
            "[239]\tvalidation_0-auc:0.870304\n",
            "[240]\tvalidation_0-auc:0.87031\n",
            "[241]\tvalidation_0-auc:0.870335\n",
            "[242]\tvalidation_0-auc:0.870444\n",
            "[243]\tvalidation_0-auc:0.870486\n",
            "[244]\tvalidation_0-auc:0.870512\n",
            "[245]\tvalidation_0-auc:0.870525\n",
            "[246]\tvalidation_0-auc:0.870561\n",
            "[247]\tvalidation_0-auc:0.870611\n",
            "[248]\tvalidation_0-auc:0.870634\n",
            "[249]\tvalidation_0-auc:0.870651\n",
            "[250]\tvalidation_0-auc:0.870677\n",
            "[251]\tvalidation_0-auc:0.870713\n",
            "[252]\tvalidation_0-auc:0.870718\n",
            "[253]\tvalidation_0-auc:0.870766\n",
            "[254]\tvalidation_0-auc:0.870788\n",
            "[255]\tvalidation_0-auc:0.87081\n",
            "[256]\tvalidation_0-auc:0.870856\n",
            "[257]\tvalidation_0-auc:0.870905\n",
            "[258]\tvalidation_0-auc:0.870939\n",
            "[259]\tvalidation_0-auc:0.87097\n",
            "[260]\tvalidation_0-auc:0.871008\n",
            "[261]\tvalidation_0-auc:0.87102\n",
            "[262]\tvalidation_0-auc:0.871049\n",
            "[263]\tvalidation_0-auc:0.871084\n",
            "[264]\tvalidation_0-auc:0.871083\n",
            "[265]\tvalidation_0-auc:0.871157\n",
            "[266]\tvalidation_0-auc:0.871191\n",
            "[267]\tvalidation_0-auc:0.87121\n",
            "[268]\tvalidation_0-auc:0.871256\n",
            "[269]\tvalidation_0-auc:0.871272\n",
            "[270]\tvalidation_0-auc:0.871294\n",
            "[271]\tvalidation_0-auc:0.871342\n",
            "[272]\tvalidation_0-auc:0.871357\n",
            "[273]\tvalidation_0-auc:0.871367\n",
            "[274]\tvalidation_0-auc:0.871388\n",
            "[275]\tvalidation_0-auc:0.871397\n",
            "[276]\tvalidation_0-auc:0.871441\n",
            "[277]\tvalidation_0-auc:0.871448\n",
            "[278]\tvalidation_0-auc:0.871474\n",
            "[279]\tvalidation_0-auc:0.871485\n",
            "[280]\tvalidation_0-auc:0.871489\n",
            "[281]\tvalidation_0-auc:0.871536\n",
            "[282]\tvalidation_0-auc:0.871585\n",
            "[283]\tvalidation_0-auc:0.871639\n",
            "[284]\tvalidation_0-auc:0.871658\n",
            "[285]\tvalidation_0-auc:0.871656\n",
            "[286]\tvalidation_0-auc:0.871659\n",
            "[287]\tvalidation_0-auc:0.871692\n",
            "[288]\tvalidation_0-auc:0.87173\n",
            "[289]\tvalidation_0-auc:0.871744\n",
            "[290]\tvalidation_0-auc:0.871761\n",
            "[291]\tvalidation_0-auc:0.871813\n",
            "[292]\tvalidation_0-auc:0.871825\n",
            "[293]\tvalidation_0-auc:0.87183\n",
            "[294]\tvalidation_0-auc:0.871842\n",
            "[295]\tvalidation_0-auc:0.871881\n",
            "[296]\tvalidation_0-auc:0.871915\n",
            "[297]\tvalidation_0-auc:0.871921\n",
            "[298]\tvalidation_0-auc:0.871957\n",
            "[299]\tvalidation_0-auc:0.871969\n",
            "[300]\tvalidation_0-auc:0.871999\n",
            "[301]\tvalidation_0-auc:0.872013\n",
            "[302]\tvalidation_0-auc:0.872028\n",
            "[303]\tvalidation_0-auc:0.872058\n",
            "[304]\tvalidation_0-auc:0.872075\n",
            "[305]\tvalidation_0-auc:0.872102\n",
            "[306]\tvalidation_0-auc:0.872131\n",
            "[307]\tvalidation_0-auc:0.872146\n",
            "[308]\tvalidation_0-auc:0.872183\n",
            "[309]\tvalidation_0-auc:0.872204\n",
            "[310]\tvalidation_0-auc:0.872237\n",
            "[311]\tvalidation_0-auc:0.872245\n",
            "[312]\tvalidation_0-auc:0.872254\n",
            "[313]\tvalidation_0-auc:0.872282\n",
            "[314]\tvalidation_0-auc:0.872307\n",
            "[315]\tvalidation_0-auc:0.872315\n",
            "[316]\tvalidation_0-auc:0.872324\n",
            "[317]\tvalidation_0-auc:0.872359\n",
            "[318]\tvalidation_0-auc:0.872382\n",
            "[319]\tvalidation_0-auc:0.872388\n",
            "[320]\tvalidation_0-auc:0.872423\n",
            "[321]\tvalidation_0-auc:0.872447\n",
            "[322]\tvalidation_0-auc:0.87248\n",
            "[323]\tvalidation_0-auc:0.872491\n",
            "[324]\tvalidation_0-auc:0.872492\n",
            "[325]\tvalidation_0-auc:0.872515\n",
            "[326]\tvalidation_0-auc:0.872529\n",
            "[327]\tvalidation_0-auc:0.872546\n",
            "[328]\tvalidation_0-auc:0.872567\n",
            "[329]\tvalidation_0-auc:0.872565\n",
            "[330]\tvalidation_0-auc:0.872576\n",
            "[331]\tvalidation_0-auc:0.872615\n",
            "[332]\tvalidation_0-auc:0.872619\n",
            "[333]\tvalidation_0-auc:0.872617\n",
            "[334]\tvalidation_0-auc:0.872629\n",
            "[335]\tvalidation_0-auc:0.872655\n",
            "[336]\tvalidation_0-auc:0.872668\n",
            "[337]\tvalidation_0-auc:0.872679\n",
            "[338]\tvalidation_0-auc:0.872698\n",
            "[339]\tvalidation_0-auc:0.872723\n",
            "[340]\tvalidation_0-auc:0.872733\n",
            "[341]\tvalidation_0-auc:0.872761\n",
            "[342]\tvalidation_0-auc:0.872771\n",
            "[343]\tvalidation_0-auc:0.872788\n",
            "[344]\tvalidation_0-auc:0.872825\n",
            "[345]\tvalidation_0-auc:0.872847\n",
            "[346]\tvalidation_0-auc:0.87287\n",
            "[347]\tvalidation_0-auc:0.872907\n",
            "[348]\tvalidation_0-auc:0.872938\n",
            "[349]\tvalidation_0-auc:0.872946\n",
            "[350]\tvalidation_0-auc:0.872961\n",
            "[351]\tvalidation_0-auc:0.872974\n",
            "[352]\tvalidation_0-auc:0.872985\n",
            "[353]\tvalidation_0-auc:0.87299\n",
            "[354]\tvalidation_0-auc:0.873003\n",
            "[355]\tvalidation_0-auc:0.873003\n",
            "[356]\tvalidation_0-auc:0.873003\n",
            "[357]\tvalidation_0-auc:0.873003\n",
            "[358]\tvalidation_0-auc:0.873003\n",
            "[359]\tvalidation_0-auc:0.873003\n",
            "[360]\tvalidation_0-auc:0.873003\n",
            "[361]\tvalidation_0-auc:0.873003\n",
            "[362]\tvalidation_0-auc:0.873003\n",
            "[363]\tvalidation_0-auc:0.873003\n",
            "[364]\tvalidation_0-auc:0.873003\n",
            "[365]\tvalidation_0-auc:0.873003\n",
            "[366]\tvalidation_0-auc:0.873003\n",
            "[367]\tvalidation_0-auc:0.873003\n",
            "[368]\tvalidation_0-auc:0.873003\n",
            "[369]\tvalidation_0-auc:0.873003\n",
            "[370]\tvalidation_0-auc:0.873003\n",
            "[371]\tvalidation_0-auc:0.873003\n",
            "[372]\tvalidation_0-auc:0.873003\n",
            "[373]\tvalidation_0-auc:0.873003\n",
            "[374]\tvalidation_0-auc:0.873003\n",
            "Stopping. Best iteration:\n",
            "[354]\tvalidation_0-auc:0.873003\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=10,\n",
              "              learning_rate=0.05, max_delta_step=0, max_depth=20,\n",
              "              min_child_weight=1, missing=None, n_estimators=500, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=9616,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHqah1POk0A4"
      },
      "source": [
        "clf_perf = roc_auc_score(y_test, clf.predict(X_test))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "bABH9WJinmIE",
        "outputId": "4b43e433-29c0-4e48-9378-886f28a1696d"
      },
      "source": [
        "algos = ['Random Forest', 'SGD Classifier', 'K Nearest Neighbors', 'Gradeient Boosting Classifier', 'XGBoost' ]\n",
        "perf = [rf_perf, sgd_perf, knc_perf, gbc_perf, clf_perf]\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "plt.bar(algos, perf)\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-gWe2A5nOiY"
      },
      "source": [
        "We can see that XGBoost gave the best roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeJ-o5RPsGFZ"
      },
      "source": [
        "## Getting predictions and generating submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWk5zonQddZy",
        "outputId": "d8821ddf-8cb0-468e-9e54-07cdcb376d15"
      },
      "source": [
        "test = pd.read_csv('ML_Artivatic_dataset/final_test.csv')\n",
        "member_id = test['member_id']\n",
        "test = test.drop(columns=['member_id'])\n",
        "\n",
        "test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "imp = SimpleImputer(strategy='median')\n",
        "test = pd.DataFrame(imp.fit_transform(test))\n",
        "\n",
        "predictions = clf.predict(test)\n",
        "predictions"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QN6o-wy3pllY",
        "outputId": "2f7bbc61-eaea-4744-b5cb-5e92dd012f3d"
      },
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['member_id'] = member_id \n",
        "submission['loan_status'] = predictions \n",
        "submission "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>member_id</th>\n",
              "      <th>loan_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11937648</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38983318</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27999917</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61514932</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59622821</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354946</th>\n",
              "      <td>19145105</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354947</th>\n",
              "      <td>46304777</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354948</th>\n",
              "      <td>903745</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354949</th>\n",
              "      <td>53032475</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354950</th>\n",
              "      <td>994245</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>354951 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        member_id  loan_status\n",
              "0        11937648            0\n",
              "1        38983318            0\n",
              "2        27999917            0\n",
              "3        61514932            0\n",
              "4        59622821            0\n",
              "...           ...          ...\n",
              "354946   19145105            0\n",
              "354947   46304777            0\n",
              "354948     903745            1\n",
              "354949   53032475            0\n",
              "354950     994245            0\n",
              "\n",
              "[354951 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz80LLdwrBUu"
      },
      "source": [
        "submission.to_csv('ML_Artivatic_dataset/submission1.csv', index=False)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGE1nHp_sMjx"
      },
      "source": [
        "## Saving the best model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktTPZnLerbhY"
      },
      "source": [
        "import pickle \n",
        "\n",
        "pickle.dump(clf, open('xgboost.dat', 'wb'))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKCSNwTgrr0i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}